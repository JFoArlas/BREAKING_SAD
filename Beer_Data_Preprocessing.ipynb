{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data\n",
    "beer_df = pd.read_csv(\"../Resources/BeerProject.csv\", encoding='unicode_escape')\n",
    "print(beer_df.shape)\n",
    "beer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ccd74e",
   "metadata": {},
   "source": [
    "## Order of Operations\n",
    "\n",
    "1. Check NA's and decide whether to remove rows and/or columns\n",
    "2. Look at data types\n",
    "3. For categorical, look at unique values and their distribution \n",
    "4. For numeric, look at simple stats (mean, med, mode etc.)\n",
    "5. Export the cleaned data\n",
    "\n",
    "\n",
    "## Unsupervised \n",
    "(see x notebook)\n",
    "1. Converting categorical columns using binning and encoding\n",
    "2. Remove the outcome column (beer type)\n",
    "3. Standardise continuous data\n",
    "4. Build an elbow curve and k-means cluster\n",
    "\n",
    "## Supervised\n",
    "(see x notebook)\n",
    "1. Converting categorical columns using binning and encoding\n",
    "2. Split training and testing\n",
    "3. Standardise continuous data\n",
    "4. Build our model \n",
    "        - start with a decision tree\n",
    "        - move to a random forest\n",
    "        - end with gradient booster \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e16c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check NA's and decide whether to remove rows and/or columns\n",
    "\n",
    "#find null values\n",
    "for column in beer_df.columns:\n",
    "    print(f\"Column {column} has {beer_df[column].isnull().sum()} null values\")\n",
    "    \n",
    "# could drop na rows, but data with na values are in review_profileName and review_text \n",
    "# these columns will not be used in either machine learning model \n",
    "# if we want to drop null rows:\n",
    "# beer_df = beer_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Look at data types\n",
    "beer_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Find duplicate entries\n",
    "print(f\"Duplicate entries: {beer_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d742a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. For categorical, look at unique values and their distribution \n",
    "beer_df.beer_style.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0068694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequency of each beer using a bar plot\n",
    "\n",
    "beer_style=beer_df.beer_style.unique()\n",
    "count=beer_df.beer_style.value_counts()\n",
    "df = pd.DataFrame({'beer_style':beer_style, 'count':count})\n",
    "\n",
    "fig = px.bar(df, x='beer_style', y='count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82cdb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. For numeric, look at simple stats (mean, med, mode etc.)\n",
    "fig = px.box(beer_df, y=[\"review_appearance\", \"review_palette\", \"review_overall\", \"review_taste\", \"review_aroma\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba06158",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(beer_df, y=[\"beer_ABV\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3209ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Export the cleaned data\n",
    "# there wasn't much to clean, so nothing to export \n",
    "# -more data pre processing will happen unique to the models we decide to ues..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae28a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
